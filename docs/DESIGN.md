## 🔍 詳細設計

### 1. 前提と非機能要件の整理

**前提**

* モデル: `gpt-oss-20b`（約21Bパラメータ、MXFP4 MoE。16GB VRAMで動く設計）([GitHub][2])
* Harmony フォーマット必須（system / developer / user / assistant / tools の構造化 + analysis/final チャンネル）([OpenAI Cookbook][1])
* 長期記憶: **埋め込み＋ベクタDBは使わない**。代わりに

  * 短いサマリ
  * メタデータ（タグ / スコア）
  * 明示的な「関連IDリンク」
    で管理。

**非機能要件**

* 24/7 常時稼働（ただし GPU/温度/電源的に現実的な duty cycle を自分で決める必要あり。ここ甘く見るとマシン死ぬ😇）
* 個人プロジェクトなので Web アクセスや高度な安全フレームワークは必須ではない（ただし違法・暴力系などは自分側で線引きしたほうが良い）。
* 将来テーマ差し替え（ぴかりん以外のIPや別ビジネス）を設定ファイル変更だけで可能にする。

---

### 2. 全体アーキテクチャ

コンポーネントをざっくり分けるとこんな感じ👇

1. **モデル実行レイヤ**

   * gpt-oss-20b 本体（HF / vLLM / Ollama / gpt-oss Triton など）([GitHub][2])
   * Harmony レンダラ＆パーサ（`openai-harmony`）([PyPI][3])

2. **エージェント・オーケストレータ**

   * プランナー（長期ロードマップとタスクキュー管理）
   * クリエイター（アイデア生成・拡張）
   * クリティック（評価・レビュー）
   * エディタ（ブラッシュアップ＆ドキュメント化）

3. **設定＆知識レイヤ**

   * 不変 IP 設定ファイル（ぴかりん「聖典」的なやつ）
   * プロジェクト設定（テーマ・目的・制約）
   * テンプレート（ビジネスモデルキャンバス、企画書テンプレ）

4. **状態＆ストレージ**

   * `runtime/ideas/`：アイデア本体 + メタデータ
   * `runtime/state/`：タスクキューやループカウンタ
   * `runtime/iterations/`：各ループのログ
   * `runtime/snapshots/`：定期スナップショット（人間レビュー用）

5. **インタフェース＆運用**

   * CLI or Web UI（最低でも CLI）
   * コマンド: `start/stop/pause/status/new-theme/review` など
   * モニタリング: ログ / 簡易ダッシュボード

---

### 3. モデル実行レイヤの設計

#### 3.1 バックエンド選択のパターン

いずれも **ローカル推論** 前提。

* **vLLM サーバ方式**

  * `vllm serve openai/gpt-oss-20b` で OpenAI 互換 API 化 ([GitHub][2])
  * Harmony を自前で扱うなら、`openai-harmony` の Python ライブラリで

    * `Conversation` を構築
    * `render_conversation_for_completion` でトークナイズ
    * `parse_messages_from_completion_tokens` で出力解析

* **Ollama 方式**

  * `ollama pull gpt-oss:20b` で手軽に動くが、Harmony のフル機能（tool call 等）は実装依存。([GitHub][2])
  * 「ひとまずテキスト生成だけできればOK」ならこれが一番ラク。
  * 将来ツール呼び出し使いたくなったら vLLM or 公式実装に移行。

* **gpt-oss 公式 Triton / Torch 実装**

  * フルコントロール可能だけど、実装は重い＆学習コスト高め。([GitHub][2])
  * 「自分で中身まで覗きたい」変態モード向け。

**このプロジェクトの現実解:**

* 最初は **Ollama か vLLM** で十分。
* 「ツール呼び出しを強く使う」段階で vLLM + Harmony の構成に寄せる設計にしとくと後で楽。

#### 3.2 Harmony メッセージ設計の基本

Harmony では:

* `system` メッセージ → モデルのメタ（You are ChatGPT..., knowledge cutoff, current date, reasoning level, 有効チャネルなど）([OpenAI Cookbook][1])
* `developer` メッセージ → 実質の「システムプロンプト」:

  * エージェントの役割
  * 出力フォーマット
  * 利用可能ツール
* `user` メッセージ → ユーザーからの入力、 or オーケストレータからの「タスク指示」

エージェント設計的には、**「IP設定ファイル＋プロジェクト設定」⇒ developer メッセージに毎回挿入** するのがポイント。

---

### 4. 設定＆知識レイヤの設計

#### 4.1 不変 IP 設定ファイル（例: `ip_profile.json`）

このファイルは **「ぴかりんが何者か」** を決めるコアで、エージェントからは読み取り専用。

フィールド例（テキストで管理）：

* `ip_name`：光の妖精ぴかりん
* `essence`：世界観・根源的コンセプト
* `visual_motifs`：色・形・アイコン
* `core_personality`：性格・喋り方
* `taboos`：絶対にやらないライン（イメージ崩壊防止用）
* `target_audience`：主なファン層
* `brand_promise`：ファンに約束する体験のコア
* `canon_examples`：既にある設定・ストーリー例の短いサマリ集

この内容を developer メッセージに、例えば

> 「# IP Spec」セクションとして貼り込む（テキスト整形はオーケストレータ側）。

**重要ツッコミ:**
ここをフワッと書くと、モデルは毎回勝手に解釈を上書きし始める。
「IPの芯が何か」は人間側でガチガチに決めておかないと、24/7 で回すほどブレてカオスになる🥺⚡

#### 4.2 プロジェクト設定ファイル（例: `project_config.json`）

こちらは **テーマ単位で変える** 想定。

フィールド例：

* `project_name`：光の妖精ぴかりんIP事業構想
* `goal_type`：例）「3年以内にマネタイズ案10個＋PoC 2個」
* `constraints`：

  * 予算レンジ
  * 法的制約
  * ローカル環境前提（外部API禁止など）
* `idea_templates`：

  * ビジネスモデルキャンバス項目
  * 収益モデルの型（サブスク、グッズ、ライセンス…）
* `iteration_policy`：

  * 1イテレーションの最大トークン
  * 探索：深化の比率（例: 60:40）
  * 停滞検知のパラメータ（後述）

`iteration_policy` はロード直後に検証し、

* `explore_ratio` と `deepening_ratio` は `explore_ratio + deepening_ratio = 1.0` を満たすこと
* `stagnation_threshold ∈ [0, 1]`
* `stagnation_runs ≥ 1`

を満たさない場合は起動時に例外を投げる。

モード選択は、累積実行数 `n = explore + deepen` に対して

* `target_explore = explore_ratio * n`
* `target_deepen = deepening_ratio * n`

を計算し、各カウントが目標を下回っている側を優先する。

停滞検知は連続サマリの Jaccard 類似度 `J(a, b) = |a ∩ b| / |a ∪ b|` を計算し、`stagnation_runs` 個の隣接ペアすべてで `J ≥ stagnation_threshold` を満たした場合に「停滞」と判断、強制的に揺さぶるタスクを挿入する。

オーケストレータは毎ループでこの設定を読み込み、developer メッセージに `# Project Config` として埋め込む。

---

### 5. エージェントロール設計

#### 5.1 ロール構成

**1) Planner（プランナー）**

* 役割: 長期ロードマップとタスクキューを管理
* 主なアウトプット:

  * 「今週やるべきアイデア深化タスクのリスト」
  * 「探索フェーズで試すべき新領域（例: Webtoon 展開, バーチャルライブ など）」

**2) Ideator（アイデア生成担当）**

* 役割: 与えられたテーマ・制約に対して新規ビジネスアイデアを構造化して生成
* アウトプット:

  * ID
  * ワンライナー
  * ターゲット
  * 提供価値
  * 収益モデル
  * 差別化要因
  * リスク

**3) Critic（批評家）**

* 役割: 各アイデアの評価・比較・弱点抽出
* アウトプット:

  * スコア（新規性 / 実現性 / ブランド適合度 etc.）
  * ボトルネック
  * 改善提案（差分が明確なもの）

**4) Editor（エディタ）**

* 役割: 有望アイデアを「人間が読める企画書」レベルまで磨く
* アウトプット:

  * 2〜3ページ相当の企画概要
  * 必要リソース・スケジュールの骨子

これらは全部 **同じ gpt-oss-20b** を使うが、Harmony の developer メッセージで

* 「あなたは現在 Planner として振る舞うこと」
* 「あなたは Ideator として、以下の形式でアイデアを出力すること」

と役割指示を切り替えて実現する。

#### 5.2 1ループ内のフロー

1ループの標準パターン:

1. **タスク選択（Planner）**

   * Task Queue から「Ready & High Priority」のものを1件選ぶ
   * なければ Planner 自身に「新タスク生成」を依頼

2. **コンテキスト構築**

   * 選んだタスクと紐づいている

     * 関連アイデア（IDで参照）
     * その要約・メタデータ
   * IP設定 / プロジェクト設定
     を developer + user メッセージにまとめる

3. **モデル呼び出し（Ideator / Critic / Editor のどれか）**

   * タスク種別に応じてロールを切り替え
   * 出力フォーマットは表形式 or JSONライクな構造をテキストで強制（パースしやすくするため）

4. **出力パース & 永続化**

   * 新アイデアなら `runtime/ideas/` に追加
   * 既存アイデアの更新なら差分計算し、 `change_log` に記録

5. **停滞チェック**（後述）

6. **次ループのタスク生成 / 既存タスク更新**

---

### 6. 状態＆ストレージ設計（非ベクタ前提）

#### 6.1 ディレクトリ構成イメージ（概念）

* `config/`

  * `ip_profile.json`（不変）
  * `project_config.json`
* `runtime/`

  * `state/`

    * `tasks.json`（タスクキュー）
    * `iteration_state.json`（ループカウンタ・モードなど）
  * `ideas/`

    * `ideas.jsonl`（1行1アイデア、ID付き）
    * `ideas_index.json`（タグ一覧・スコア）
  * `iterations/`

    * `YYYYMMDD_HHMM_iteration.json`（1ループ分の入出力ログ）
  * `snapshots/`

    * `YYYYMMDD_portfolio.md`（人間レビュー用まとめ）

#### 6.2 アイデアのデータ構造（例）

フィールドイメージ（テキストの記述ルールとして定義）:

* `id`（string）
* `title`（ワンライナー）
* `summary`（200〜300文字）
* `target_audience`（箇条書き）
* `value_proposition`
* `revenue_model`
* `brand_fit_score`（1〜5）
* `novelty_score`（1〜5）
* `feasibility_score`（1〜5）
* `status`（idea / shortlisted / archived）
* `tags`（"merch", "vtuber", "event" など）

**ポイント:**

* **summary / tags / scores が、埋め込みなしでの「検索キー」になる**。
* タスクに「関連アイデアID」をひもづけておけば、

  * 「タスク → アイデアID → ideas.jsonl から該当だけ読み込む」
    で十分回せる。

#### 6.3 タスクのデータ構造（例）

* `id`
* `type`（"generate_ideas" / "refine_idea" / "compare_portfolio" / "snapshot" など）
* `priority`（数値）
* `related_idea_ids`（配列）
* `status`（ready / running / done / blocked）
* `created_at` / `last_run_at`
* `meta`（パラメータ: 何個生成するかなど）

---

### 7. 停滞・ループ防止ロジック

ここ甘いと、24/7 が **「同じことを言葉だけ変えて繰り返す地獄」** になるので要注意👹

#### 7.1 差分チェック（擬似テキスト類似度）

埋め込みなしでできる範囲で:

* **シンプルな手法：**

  * 前バージョンと新バージョンの本文を

    * トークン（単語）単位で比較し、
    * 共有単語の割合（Jaccardっぽい指標）を出す
  * 類似度が例えば `0.9以上` なら「ほぼ同じ」と判定

* **ルール:**

  * 同じアイデアに対して「ほぼ同じ更新」が `N回`（例: 3回）続いたら

    * そのタスクは `stalled` 状態に変更
    * 新しいタスク: `shake_up_idea` を生成する

`shake_up_idea` タスクでは developer メッセージに

* 「これまでと明確に異なる方向性を少なくとも2つ提示せよ」
* 「過去3回の修正内容を繰り返さないこと」
  などの制約を入れる。

#### 7.2 モード切り替え（探索 vs 深化）

ループごとに **「どのモードで動くか」** を Scheduler が決める:

* **Explore（探索モード）**

  * 新アイデア生成がメイン
  * 既存スコア分布を見て、「このゾーンが手薄」と判断した領域を狙う
  * 例：グッズばかり増えているなら、デジタルサービス系を強制

* **Exploit / Deepen（深化モード）**

  * shortlisted な有望アイデアの具体化
  * 収益予測の粗モデルやリソース見積もりなど

プロジェクト設定に「探索:深化比率」を持たせておき、

* 停滞が続いている時は探索比率を上げる
* 逆にアイデアが散らかりすぎたら深化比率を上げる
  といったポリシーを反映。

#### 7.3 メタ自己評価ステップ

定期（例: 100ループごと）タスクとして:

* 「直近Nループ分のスナップショット要約」をモデルに渡し、
* 以下を評価させるメタタスクを走らせる:

  * 同じ論点を何度も繰り返していないか
  * アイデアの多様性は増えているか
  * ブランドの芯がブレていないか

そして、

* 「もし停滞していると自分で判断した場合、新しいフレームワークや視点を3つ提案せよ」
  と指示する。

**注意ポイント:**
この自己評価も「自分に甘い回答」をしがちなので、

* 過去スコアの分布（平均・分散）など「定量情報」だけは Python 側で計算してから提示して、
* モデルには解釈だけやらせる、くらいがちょうどいい。

---

### 8. ユーザーインタフェース＆運用

#### 8.1 CLI コマンドの例（概念）

* `agent start`

  * 24/7 ループ開始（バックグラウンドプロセス化）

* `agent stop`

  * 適切に state を保存して終了

* `agent status`

  * 現在のループカウンタ、稼働モード、キュー中のタスク数

* `agent review`

  * 最新スナップショットを Markdown でまとめて表示

* `agent new-theme --config path/to/new_project_config.json`

  * プロジェクト設定の差し替え（IP設定は不変のままにすることも可）



  * 次の深化フェーズで優先される
